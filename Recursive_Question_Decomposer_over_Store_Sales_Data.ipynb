{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1wlgUSr2RRxPKYnTsV2AkttuZDiIl5vRM",
      "authorship_tag": "ABX9TyNIyHS7EpeNRwofEOZZu1XC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakshitaa4/Recursive_Question_Decomposer_over_Store_Sales_Data/blob/main/Recursive_Question_Decomposer_over_Store_Sales_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recursive Question Decomposer over Store Sales Data"
      ],
      "metadata": {
        "id": "XoPkXzugY4NK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Install required packages\n",
        "!pip install -q -U langgraph langchain langchain-google-genai langchain-experimental pandas python-dotenv"
      ],
      "metadata": {
        "id": "Fz3xrGtB3zMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Authentication: Connecting to Gemini\n",
        "This is a critical step where we authorize our Colab notebook to access your Google AI account to use gemini.\n",
        "\n",
        "- Go to Google AI Studio: https://aistudio.google.com/\n",
        "- Click \"Get API key\" and create a new project/key. Copy the key.\n",
        "- In Colab, click the key icon (ðŸ”‘) on the left sidebar (Secrets Manager).\n",
        "- Click \"+ Add new secret\", name it GOOGLE_API_KEY, and paste your Gemini API key. Toggle the switch to make it accessible."
      ],
      "metadata": {
        "id": "_nnNzNxPY9OF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Part 1: Your Setup (with necessary additions) ===\n",
        "\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import logging\n",
        "import pandas as pd\n",
        "from typing import TypedDict, List, Dict, Optional\n",
        "\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_experimental.agents import create_pandas_dataframe_agent\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from google.colab import drive, userdata\n",
        "\n",
        "# --- Configuration & Setup ---\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "try:\n",
        "    os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
        "    print(\"Google API Key loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to load Google API Key. Error: {e}\")\n",
        "\n",
        "llm = None\n",
        "try:\n",
        "    # Using the user-specified model name\n",
        "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.0)   # you may change the model as you please\n",
        "    print(\"LLM 'gemini-2.5-flash' initialized.\")\n",
        "except Exception as e:\n",
        "    print(f\"CRITICAL: LLM 'llm' is NOT initialized. Error: {e}\")\n",
        "\n",
        "# --- Data Loading and Preparation ---\n",
        "df = None\n",
        "pandas_agent = None\n",
        "try:\n",
        "    print(\"\\nMounting Google Drive...\")\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    excel_file_path = r\"/content/drive/MyDrive/langgraph assignment/Demo Sales Data.xlsx\"    #change this according to where your file is saved on the drive\n",
        "    df = pd.read_excel(excel_file_path, sheet_name=0)\n",
        "    print(f\"Data loaded successfully from {excel_file_path}\")\n",
        "\n",
        "    # --- Sanitizing column names for agent compatibility ---\n",
        "    def sanitize_column_name(col_name):\n",
        "        name = col_name.lower()\n",
        "        name = re.sub(r'[^a-z0-9]+', '_', name)\n",
        "        return name.strip('_')\n",
        "\n",
        "    original_columns = df.columns.tolist()\n",
        "    df.columns = [sanitize_column_name(col) for col in original_columns]\n",
        "    sanitized_columns = df.columns.tolist()\n",
        "\n",
        "    print(\"\\n--- Column Name Sanitation ---\")\n",
        "    for orig, new in zip(original_columns, sanitized_columns):\n",
        "        print(f\"'{orig}' -> '{new}'\")\n",
        "\n",
        "    if 'retail' in df.columns and 'qty_sold' in df.columns:\n",
        "        df['revenue'] = df['retail'] * df['qty_sold']\n",
        "        print(\"'revenue' column (from retail * qty_sold) calculated and added.\")\n",
        "\n",
        "    # Initialize the Pandas Agent AFTER the dataframe is loaded and prepared\n",
        "    if llm and df is not None:\n",
        "        pandas_agent = create_pandas_dataframe_agent(\n",
        "            llm,\n",
        "            df,\n",
        "            verbose=False,\n",
        "            agent_executor_kwargs={\"handle_parsing_errors\": True},\n",
        "            allow_dangerous_code=True\n",
        "        )\n",
        "        print(\"\\nPandas DataFrame Agent initialized successfully.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nError loading or processing data: {e}\")\n",
        "\n",
        "# In-memory cache for repeated sub-questions\n",
        "memoization_cache = {}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ok8Ujlkp8xUX",
        "outputId": "c249071c-4500-41bd-f469-d08292cf0621"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google API Key loaded successfully.\n",
            "LLM 'gemini-2.5-flash' initialized.\n",
            "\n",
            "Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "Data loaded successfully from /content/drive/MyDrive/langgraph assignment/Demo Sales Data.xlsx\n",
            "\n",
            "--- Column Name Sanitation ---\n",
            "'Store Name' -> 'store_name'\n",
            "'Description' -> 'description'\n",
            "'Department' -> 'department'\n",
            "'Qty Sold' -> 'qty_sold'\n",
            "'Cost' -> 'cost'\n",
            "'Retail' -> 'retail'\n",
            "'Total Retail' -> 'total_retail'\n",
            "'Margin' -> 'margin'\n",
            "'Profit' -> 'profit'\n",
            "'revenue' column (from retail * qty_sold) calculated and added.\n",
            "\n",
            "Pandas DataFrame Agent initialized successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# printing first 5 rows of the sheet\n",
        "df.head()"
      ],
      "metadata": {
        "id": "SiunCIAGTHdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  testing whether pandas agent is working\n",
        "pandas_agent.invoke({\"input\": \"What is the total revenue for the 'SMOKE SHOP' department?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5OrT3LeEkm5",
        "outputId": "84438c50-c2c4-41c2-b9e3-7859b78e601a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': \"What is the total revenue for the 'SMOKE SHOP' department?\",\n",
              " 'output': '60577.99999999999'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing whether llm is working\n",
        "llm.invoke(\"What is the capital of Zurich?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYTuWx0eFD-z",
        "outputId": "5326d16f-8a1d-4916-b30b-193661cd7ecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"The capital of the Canton of Zurich is **Zurich** itself.\\n\\nIt's both the name of the canton (a state within Switzerland) and its largest city, which serves as its capital and administrative center.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--65c72256-dbbe-40ce-8d89-3770925454c3-0', usage_metadata={'input_tokens': 8, 'output_tokens': 44, 'total_tokens': 244, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 192}})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Graph State and Node Functions ===\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "    original_question: str\n",
        "    questions_to_process: List[str]\n",
        "    question_answer_pairs: Dict[str, str]\n",
        "    final_answer: str\n",
        "    logs: List[Dict]\n",
        "    decision: Optional[str]\n",
        "\n",
        "# this is just the starting node\n",
        "def start_node(state: GraphState) -> Dict:\n",
        "    logger.info(\"Starting a new question-answering process.\")\n",
        "    state[\"logs\"].append({\"step\": \"Start\", \"output\": \"Graph execution started.\"})\n",
        "    return {}\n",
        "\n",
        "# for determining whether the query is atomic or complex\n",
        "def complexity_node(state: GraphState) -> Dict:\n",
        "    question = state[\"questions_to_process\"][0]\n",
        "    logger.info(f\"Deciding complexity for: '{question}'\")\n",
        "    prompt = f\"You are a query classifier. Determine if a question is 'Atomic' or 'Complex'. Question: \\\"{question}\\\". Respond with only 'Atomic' or 'Complex'.\"\n",
        "    decision = llm.invoke(prompt).content.strip()\n",
        "    logger.info(f\"Decision: '{decision}'\")\n",
        "    state[\"logs\"].append({\"step\": \"Complexity Decision\", \"input\": question, \"output\": decision})\n",
        "    return {\"decision\": decision}\n",
        "\n",
        "# for decomposing complex queries into sub queries for simplification\n",
        "def decomposition_node(state: GraphState) -> Dict:\n",
        "    question = state[\"questions_to_process\"].pop(0)\n",
        "    logger.info(f\"Decomposing complex question: '{question}'\")\n",
        "    prompt = f\"\"\"You are an expert query decomposer. Break down a complex question into a series of simpler, atomic sub-questions. Output ONLY a valid JSON list of strings.\n",
        "                  ---\n",
        "                  Example 1:\n",
        "                  Original Question: \"Which store is most profitable, and what is its top selling item by quantity?\"\n",
        "                  Output:\n",
        "                  [\"What is the total profit for each store?\", \"Which store has the highest total profit?\", \"For the most profitable store, what is its item description with the highest quantity sold?\"]\n",
        "                  ---\n",
        "                  Example 2:\n",
        "                  Original Question: \"Compare the total revenue of the 'SMOKE SHOP' and 'CO : BAKERY' departments.\"\n",
        "                  Output:\n",
        "                  [\"What is the total revenue for the 'SMOKE SHOP' department?\", \"What is the total revenue for the 'CO : BAKERY' department?\"]\n",
        "                  ---\n",
        "                  Original Question: {question}\n",
        "                  Output:\n",
        "                  \"\"\"\n",
        "    response = llm.invoke(prompt).content.strip()\n",
        "    try:\n",
        "        cleaned_response = re.sub(r\"```json\\n?|```\", \"\", response)\n",
        "        sub_questions = json.loads(cleaned_response)\n",
        "    except json.JSONDecodeError:\n",
        "        logger.warning(f\"Failed to parse JSON for decomposition. Fallback to original. Response: {response}\")\n",
        "        sub_questions = [question]\n",
        "\n",
        "    new_questions_to_add = []\n",
        "    for q in sub_questions:\n",
        "        if q not in state[\"questions_to_process\"] and q not in state[\"question_answer_pairs\"]:\n",
        "            new_questions_to_add.append(q)\n",
        "        else:\n",
        "            logger.info(f\"Skipping redundant question: '{q}'\")\n",
        "\n",
        "    state[\"logs\"].append({\"step\": \"Decomposition\", \"input\": question, \"output\": new_questions_to_add})\n",
        "    state[\"questions_to_process\"].extend(new_questions_to_add)\n",
        "    return {}\n",
        "\n",
        "# for resolving the subquery or atomic query by passing it to the pandas agent\n",
        "def resolver_node(state: GraphState) -> Dict:\n",
        "    question = state[\"questions_to_process\"].pop(0)\n",
        "    logger.info(f\"Resolving atomic question: '{question}'\")\n",
        "    if question in memoization_cache:\n",
        "        logger.info(\"Found answer in cache.\")\n",
        "        answer = memoization_cache[question]\n",
        "    else:\n",
        "        response = pandas_agent.invoke({\"input\": question})\n",
        "        try:\n",
        "            answer = response.get('output') or response.content or str(response)\n",
        "        except Exception:\n",
        "            answer = str(response)\n",
        "        memoization_cache[question] = answer\n",
        "    logger.info(f\"Answer: {answer}\")\n",
        "    state[\"question_answer_pairs\"][question] = answer\n",
        "    state[\"logs\"].append({\"step\": \"Data Resolver\", \"input\": question, \"output\": answer})\n",
        "    return {}\n",
        "\n",
        "# for forming the final answer using\n",
        "def aggregator_node(state: GraphState) -> Dict:\n",
        "    logger.info(\"Aggregating answers for the final response.\")\n",
        "    original_question = state[\"original_question\"]\n",
        "    sub_answers = json.dumps(state[\"question_answer_pairs\"], indent=2)\n",
        "    prompt = f\"Synthesize a final, user-friendly answer from the following data. Original Question: {original_question}\\n\\nSub-Questions and Answers:\\n{sub_answers}\\n\\nFinal Answer:\"\n",
        "    final_answer = llm.invoke(prompt).content.strip()\n",
        "    logger.info(f\"Final Synthesized Answer: {final_answer}\")\n",
        "    state[\"logs\"].append({\"step\": \"Aggregation\", \"input\": sub_answers, \"output\": final_answer})\n",
        "    # FIX 1: Explicitly return the update for 'final_answer' to ensure it's saved.\n",
        "    return {\"final_answer\": final_answer}\n",
        "\n",
        "# for deciding whether to resolve or decompose\n",
        "def decide_path(state: GraphState) -> str:\n",
        "    return \"decompose\" if state['decision'] == \"Complex\" else \"resolve\"\n",
        "\n",
        "#if there are questions left to process\n",
        "def should_continue(state: GraphState) -> str:\n",
        "    return \"continue_processing\" if state[\"questions_to_process\"] else \"aggregate\""
      ],
      "metadata": {
        "id": "0zA0M7AkVbnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Graph Construction & Execution ===\n",
        "\n",
        "workflow = StateGraph(GraphState)\n",
        "workflow.add_node(\"start_node\", start_node)\n",
        "workflow.add_node(\"complexity_node\", complexity_node)\n",
        "workflow.add_node(\"decomposition_node\", decomposition_node)\n",
        "workflow.add_node(\"resolver_node\", resolver_node)\n",
        "workflow.add_node(\"aggregator_node\", aggregator_node)\n",
        "workflow.set_entry_point(\"start_node\")\n",
        "workflow.add_edge(\"start_node\", \"complexity_node\")\n",
        "workflow.add_conditional_edges(\"complexity_node\", decide_path, {\"decompose\": \"decomposition_node\", \"resolve\": \"resolver_node\"})\n",
        "workflow.add_edge(\"decomposition_node\", \"resolver_node\")\n",
        "workflow.add_edge(\"aggregator_node\", END)\n",
        "workflow.add_conditional_edges(\"resolver_node\", should_continue, {\"continue_processing\": \"complexity_node\", \"aggregate\": \"aggregator_node\"})\n",
        "app = workflow.compile()\n",
        "\n",
        "def run_graph(question: str):\n",
        "    initial_state = { \"original_question\": question, \"questions_to_process\": [question], \"question_answer_pairs\": {}, \"final_answer\": \"\", \"logs\": [], \"decision\": None }\n",
        "    memoization_cache.clear()\n",
        "    final_state = app.invoke(initial_state)\n",
        "    output_json = {\n",
        "        \"original_question\": final_state[\"original_question\"],\n",
        "        \"final_answer\": final_state[\"final_answer\"],\n",
        "        \"sub_questions_and_answers\": final_state[\"question_answer_pairs\"],\n",
        "        \"logs\": final_state[\"logs\"]\n",
        "    }\n",
        "    return json.dumps(output_json, indent=2)\n",
        "\n",
        "# === Part 4: User Interaction ===\n",
        "if pandas_agent and llm:\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"Recursive Question Decomposer is Ready!\")\n",
        "    print(\"=\"*50)\n",
        "    default_question = \"Which store has the highest profit, and what is the total revenue for the 'CO : HOT FOOD' department in that store?\"\n",
        "    user_question = input(f\"Please enter your analytical question (or press Enter for default):\\n> \")\n",
        "    if not user_question:\n",
        "        print(f\"\\nNo question entered. Running with default:\\n'{default_question}'\")\n",
        "        user_question = default_question\n",
        "    final_json_output = run_graph(user_question)\n",
        "    print(\"\\n\\n--- FINAL OUTPUT ---\")\n",
        "    print(final_json_output)\n",
        "else:\n",
        "    print(\"\\nCould not run the application because the LLM or the Pandas Agent failed to initialize.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFUyRrUf7mVu",
        "outputId": "a36d8596-c599-4e01-edda-8a6f5db8675e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Recursive Question Decomposer is Ready!\n",
            "==================================================\n",
            "Please enter your analytical question (or press Enter for default):\n",
            "> Which store had the highest average basket size in March 2023?\n",
            "\n",
            "\n",
            "--- FINAL OUTPUT ---\n",
            "{\n",
            "  \"original_question\": \"Which store had the highest average basket size in March 2023?\",\n",
            "  \"final_answer\": \"Due to the available data not containing a date column or individual transaction details, it was not possible to determine the average basket size specifically for March 2023 or in the traditional sense of items per customer transaction.\\n\\nHowever, interpreting \\\"average basket size\\\" as the average quantity of items sold per product entry for each store, the store with the highest average was **Golden LLC**.\",\n",
            "  \"sub_questions_and_answers\": {\n",
            "    \"What is the average basket size for each store in March 2023?\": \"I cannot calculate the \\\"average basket size for each store in March 2023\\\" because:\\n1. There is no date column in the dataframe to filter for \\\"March 2023\\\".\\n2. The data is aggregated by item and store, not by individual transactions, making it impossible to determine the number of items or total value per customer basket.\\n\\nPlease clarify what \\\"average basket size\\\" should represent given the available columns, or if there's another way you'd like to interpret the data.\",\n",
            "    \"What is the average basket size for each store?\": \"The average basket size for each store, interpreted as the average quantity of items sold per product entry, is as follows:\\nBOULDER LLC: 75.34\\nCEDAR LLC: 68.84\\nCHEYENNE LLC: 69.60\\nCOLFAX LLC: 57.15\\nGolden LLC: 80.09\\nHAWK LLC: 62.23\\nLITTLETON LLC: 49.91\\nWHEAT LLC: 56.27\\nZuni LLC: 74.07\",\n",
            "    \"Which store has the highest average basket size?\": \"Golden LLC\"\n",
            "  },\n",
            "  \"logs\": [\n",
            "    {\n",
            "      \"step\": \"Start\",\n",
            "      \"output\": \"Graph execution started.\"\n",
            "    },\n",
            "    {\n",
            "      \"step\": \"Complexity Decision\",\n",
            "      \"input\": \"Which store had the highest average basket size in March 2023?\",\n",
            "      \"output\": \"Complex\"\n",
            "    },\n",
            "    {\n",
            "      \"step\": \"Decomposition\",\n",
            "      \"input\": \"Which store had the highest average basket size in March 2023?\",\n",
            "      \"output\": [\n",
            "        \"What is the average basket size for each store in March 2023?\",\n",
            "        \"Which store has the highest average basket size?\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"step\": \"Data Resolver\",\n",
            "      \"input\": \"What is the average basket size for each store in March 2023?\",\n",
            "      \"output\": \"I cannot calculate the \\\"average basket size for each store in March 2023\\\" because:\\n1. There is no date column in the dataframe to filter for \\\"March 2023\\\".\\n2. The data is aggregated by item and store, not by individual transactions, making it impossible to determine the number of items or total value per customer basket.\\n\\nPlease clarify what \\\"average basket size\\\" should represent given the available columns, or if there's another way you'd like to interpret the data.\"\n",
            "    },\n",
            "    {\n",
            "      \"step\": \"Complexity Decision\",\n",
            "      \"input\": \"Which store has the highest average basket size?\",\n",
            "      \"output\": \"Complex\"\n",
            "    },\n",
            "    {\n",
            "      \"step\": \"Decomposition\",\n",
            "      \"input\": \"Which store has the highest average basket size?\",\n",
            "      \"output\": [\n",
            "        \"What is the average basket size for each store?\",\n",
            "        \"Which store has the highest average basket size?\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"step\": \"Data Resolver\",\n",
            "      \"input\": \"What is the average basket size for each store?\",\n",
            "      \"output\": \"The average basket size for each store, interpreted as the average quantity of items sold per product entry, is as follows:\\nBOULDER LLC: 75.34\\nCEDAR LLC: 68.84\\nCHEYENNE LLC: 69.60\\nCOLFAX LLC: 57.15\\nGolden LLC: 80.09\\nHAWK LLC: 62.23\\nLITTLETON LLC: 49.91\\nWHEAT LLC: 56.27\\nZuni LLC: 74.07\"\n",
            "    },\n",
            "    {\n",
            "      \"step\": \"Complexity Decision\",\n",
            "      \"input\": \"Which store has the highest average basket size?\",\n",
            "      \"output\": \"Complex\"\n",
            "    },\n",
            "    {\n",
            "      \"step\": \"Decomposition\",\n",
            "      \"input\": \"Which store has the highest average basket size?\",\n",
            "      \"output\": [\n",
            "        \"Which store has the highest average basket size?\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"step\": \"Data Resolver\",\n",
            "      \"input\": \"Which store has the highest average basket size?\",\n",
            "      \"output\": \"Golden LLC\"\n",
            "    },\n",
            "    {\n",
            "      \"step\": \"Aggregation\",\n",
            "      \"input\": \"{\\n  \\\"What is the average basket size for each store in March 2023?\\\": \\\"I cannot calculate the \\\\\\\"average basket size for each store in March 2023\\\\\\\" because:\\\\n1. There is no date column in the dataframe to filter for \\\\\\\"March 2023\\\\\\\".\\\\n2. The data is aggregated by item and store, not by individual transactions, making it impossible to determine the number of items or total value per customer basket.\\\\n\\\\nPlease clarify what \\\\\\\"average basket size\\\\\\\" should represent given the available columns, or if there's another way you'd like to interpret the data.\\\",\\n  \\\"What is the average basket size for each store?\\\": \\\"The average basket size for each store, interpreted as the average quantity of items sold per product entry, is as follows:\\\\nBOULDER LLC: 75.34\\\\nCEDAR LLC: 68.84\\\\nCHEYENNE LLC: 69.60\\\\nCOLFAX LLC: 57.15\\\\nGolden LLC: 80.09\\\\nHAWK LLC: 62.23\\\\nLITTLETON LLC: 49.91\\\\nWHEAT LLC: 56.27\\\\nZuni LLC: 74.07\\\",\\n  \\\"Which store has the highest average basket size?\\\": \\\"Golden LLC\\\"\\n}\",\n",
            "      \"output\": \"Due to the available data not containing a date column or individual transaction details, it was not possible to determine the average basket size specifically for March 2023 or in the traditional sense of items per customer transaction.\\n\\nHowever, interpreting \\\"average basket size\\\" as the average quantity of items sold per product entry for each store, the store with the highest average was **Golden LLC**.\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2u631tpWSkW5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}